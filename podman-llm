#!/bin/bash

available() {
  command -v "$1" > /dev/null
}

select_container_manager() {
  if available podman; then
    conman_bin="podman"
    return 0
  elif available docker; then
    conman_bin="docker"
    return 0
  fi

  conman_bin="podman"
}

image_available() {
  [ -n "$("${conman[@]}" images -q "$image_name" 2> /dev/null)" ]
}

check_if_in_hf_db() {
  local host="raw.githubusercontent.com"
  local url="https://$host/ericcurtin/podman-llm/main/hf-db/$image_name"
  local image_data
  if ! image_available && image_data="$(curl -fsSL "$url")"; then
    local hf_repo
    hf_repo="$(echo "$image_data" | sed -ne "s/^hf-repo\s//pg" | xargs)"
    local model
    model="$(echo "$image_data" | sed -ne "s/^model\s//pg" | xargs)"
    local containerfile="FROM quay.io/podman-llm/podman-llm:41
RUN huggingface-cli download $hf_repo $model
RUN ln -s \$(huggingface-cli download $hf_repo $model) /root/$model
LABEL MODEL=/root/$model"
    echo "$containerfile" | "${conman[@]}" build "$VOL" -t "$image_name" -
  fi
}

get_model() {
  "${conman[@]}" inspect -f '{{ index .Config.Labels "MODEL"}}' "$image_name"
}

get_dangling_images() {
  "${conman[@]}" images --filter "dangling=true" -q --no-trunc
}

rm_dir() {
  xargs dirname
}

get_model_dir() {
  "${conman_run[@]}" "$image_name" readlink -f "$model" | rm_dir | rm_dir
}

run_prep() {
  local host_hf="$HOME/.cache/huggingface/"
  mkdir -p "$host_hf"
  VOL="-v$host_hf:/root/.cache/huggingface/"
  conman_run=("${conman[@]}" "run" "--rm" "-it")
  conman_run+=("--security-opt=label=disable" "-v$HOME:$HOME" "-v/tmp:/tmp")
  conman_run+=("$VOL")
}

rm_cli() {
  local image_name="$1"
  local model
  model="$(get_model)"

  # To be completed, only delete the directory once all associated images, 3b,
  # latest, etc. are removed
  if false; then
    local dir_to_rm
    dir_to_rm=$(get_model_dir)
    "${conman_run[@]}" "$image_name" rm -rf "$dir_to_rm" || true
  fi

  "${conman[@]}" rmi -f "$image_name"
  get_dangling_images | xargs -r "${conman[@]}" rmi -f
}

build_cli() {
  local image_name="$1"

  run_prep
  exec "${conman[@]}" build "$VOL" -t "$image_name" .
}

serve_cli() {
  local image_name="$1"

  run_prep
  check_if_in_hf_db
  local model
  model="$(get_model)"
  exec "${conman_run[@]}" -p 8080:8080 "$image_name" llama-server -m "$model"
}

get_llm_store() {
  if [ "$EUID" -eq 0 ]; then
    llm_store="/var/lib/podman-llm/storage"
    return 0
  fi

  llm_store="$HOME/.local/share/podman-llm/storage"
}

pull_cli() {
  local image_name="$1"

  run_prep
  check_if_in_hf_db
}

run_cli() {
  local image_name="$2"

  run_prep

  local args=""
  if [ "$#" -gt 2 ] && [ -n "$3" ]; then
    args=("$3")
  else
    check_if_in_hf_db
    local model
    model="$(get_model)"
    args=("llama-main" "-m" "$model" "--log-disable" "--instruct")
  fi

  exec "${conman_run[@]}" "$image_name" "${args[@]}"
}

usage() {
  echo "Usage:"
  echo "  $(basename "$0") COMMAND"
  echo
  echo "Commands:"
  echo "  run MODEL      Run a model"
  echo "  pull MODEL     Pull a model"
  echo "  serve MODEL    Serve a model on port 8080"
  echo "  list|ls        List models"
  echo "  rm MODEL       Remove a model"
  echo "  build MODEL    Build a model from a Containerfile"
}

main() {
  set -eu -o pipefail

  local conman_bin
  select_container_manager
  local llm_store
  get_llm_store
  local conman=("$conman_bin" "--root" "$llm_store")
  local conman_run
  if [ "$1" = "run" ]; then
    run_cli "$@"
  elif [ "$1" = "pull" ]; then
    pull_cli "$2"
  elif [ "$1" = "serve" ]; then
    serve_cli "$2"
  elif [ "$1" = "list" ] || [ "$1" = "ls" ]; then
    exec "${conman[@]}" images -flabel=MODEL
  elif [ "$1" = "rm" ]; then
    rm_cli "$2"
  elif [ "$1" = "build" ]; then
    build_cli "$2"
  else
    usage
    return 1
  fi
}

main "$@"

