#!/bin/bash

available() {
  command -v $1 > /dev/null
}

select_container_manager() {
  if available podman; then
    echo "podman"
  elif available docker; then
    echo "docker"
  else
    echo "podman"
  fi
}

image_available() {
  [ -n "$($conman images -q $IMAGE_NAME 2> /dev/null)" ]
}

check_if_in_hf_db() {
  local vol="$1"
  local host="raw.githubusercontent.com"
  local url="https://$host/ericcurtin/podman-llm/main/hf-db/$IMAGE_NAME"
  if ! image_available && local image_data="$(curl -fsSL $url)"; then
    local hf_repo="$(echo "$image_data" | sed -ne "s/^hf-repo\s//pg" | xargs)"
    local model="$(echo "$image_data" | sed -ne "s/^model\s//pg" | xargs)"
    local containerfile="$(echo "FROM quay.io/podman-llm/podman-llm:41
RUN huggingface-cli download $hf_repo $model
RUN ln -s \$(huggingface-cli download $hf_repo $model) /root/$model
LABEL MODEL=/root/$model")"
    echo "$containerfile" | $conman build $vol -t $IMAGE_NAME -
  fi
}

get_model() {
  $conman inspect -f '{{ index .Config.Labels "MODEL"}}' $IMAGE_NAME
}

rm_cli() {
  IMAGE_NAME="$1"
  local model="$(get_model)"

  # To be completed, only delete the directory once all associated images, 3b,
  # latest, etc. are removed
  if false; then
    local dir_to_rm=$($conman_run $IMAGE_NAME readlink -f $model | xargs dirname | xargs dirname)
    $conman_run $IMAGE_NAME rm -rf "$dir_to_rm" || true
  fi

  $conman rmi -f "$IMAGE_NAME"
  $conman images --filter "dangling=true" -q --no-trunc | xargs $conman rmi -f
}

build_cli() {
  IMAGE_NAME="$1"
  $conman build $vol -t $IMAGE_NAME .
}

get_llm_store() {
  local llm_store="--root"
  if [ "$EUID" -eq 0 ]; then
    llm_store+=" /var/lib/podman-llm/storage"
  else
    llm_store+=" $HOME/.local/share/podman-llm/storage"
  fi

  echo "$llm_store"
}

main() {
  set -eu -o pipefail

  local llm_store="$(get_llm_store)"
  local conman="$(select_container_manager) $llm_store"
  local vol="-v$HOME/.cache/huggingface/:/root/.cache/huggingface/"
  local conman_run="$conman run --rm -it --security-opt=label=disable"
  conman_run+=" -v"$HOME":"$HOME" -v/tmp:/tmp $vol"
  if [ "$1" = "run" ]; then
    IMAGE_NAME="$2"
    local args=""
    if [ "$#" -gt 2 ] && [ -n "$3" ]; then
      args="$3"
    else
      check_if_in_hf_db "$vol"
      local model="$(get_model)"
      args="llama-main -m $model --log-disable --instruct"
    fi

    $conman_run $IMAGE_NAME $args
  elif [ "$1" = "pull" ]; then
    IMAGE_NAME="$2"
    check_if_in_hf_db "$vol"
  elif [ "$1" = "serve" ]; then
    IMAGE_NAME="$2"
    check_if_in_hf_db "$vol"
    local model="$(get_model)"
    args="llama-main -m $model --log-disable --instruct"
    $conman_run -p 8080:8080 $IMAGE_NAME llama-server -m $model
  elif [ "$1" = "list" ] || [ "$1" = "ls" ]; then
    $conman images -flabel=MODEL
  elif [ "$1" = "rm" ]; then
    rm_cli "$2"
  elif [ "$1" = "build" ]; then
    build_cli "$2"
  else
    echo "Usage: podman-llm [run|pull|serve|list|rm|build] [image_name]"
    return 1
  fi
}

main "$@"

