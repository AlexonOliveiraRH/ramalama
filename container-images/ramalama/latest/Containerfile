FROM centos:stream9

RUN mkdir -p /models
RUN dnf install -y git jq procps-ng vim vulkan-headers vulkan-loader-devel \
      glslc glslang python3-pip dnf-plugins-core \
      python3-dnf-plugin-versionlock cmake gcc-c++ libcurl-devel \
      vulkan-tools && \
    dnf clean all && \
    rm -rf /var/cache/*dnf*

RUN pip install "huggingface_hub[cli]==0.24.2"

ENV GGML_CCACHE=0

RUN git clone -b ramalama https://github.com/ericcurtin/llama.cpp.git && \
    cd llama.cpp && \
    cmake -B build -DGGML_CCACHE=0 && \
    cmake --build build --config Release -j $(nproc) && \
    cd build/bin && \
    for file in *; do \
      if [ -f "$file" ] && [ -x "$file" ] && [[ "$file" == "llama-*" ]]; then \
        mv "$file" "/usr/bin/$file"; \
      fi; \
    done; \
    cd / && \
    rm -rf llama.cpp
