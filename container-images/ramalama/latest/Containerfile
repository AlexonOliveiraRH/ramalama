FROM registry.access.redhat.com/ubi9/ubi:9.4

# vulkan-headers vulkan-loader-devel vulkan-tools glslc glslang python3-pip mesa-libOpenCL-$MESA_VER.aarch64
RUN dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm && \
    crb enable && \
    dnf install -y epel-release && \
    dnf --enablerepo=ubi-9-appstream-rpms install -y git procps-ng vim \
      dnf-plugins-core python3-dnf-plugin-versionlock cmake gcc-c++ \
      python3-pip && \
    dnf clean all && \
    rm -rf /var/cache/*dnf*

RUN /usr/bin/python3 --version
RUN pip install "huggingface_hub[cli]==0.24.2"
RUN pip install "omlmd==0.1.4"

ENV LLAMA_CCACHE=0

RUN git clone -b ramalama https://github.com/ericcurtin/llama.cpp.git && \
    cd llama.cpp && \
    cmake -B build -DLLAMA_CCACHE=0 && \
    cmake --build build --config Release -j $(nproc) && \
    cd build/bin && \
    for file in *; do \
      if [ -f "$file" ] && [ -x "$file" ]; then \
        echo "$file" && \
        mv "$file" /usr/bin/llama-"$file"; \
      fi; \
    done; \
    cd / && \
    rm -rf llama.cpp

RUN git clone https://github.com/ggerganov/whisper.cpp.git && \
    cd whisper.cpp && \
    git reset --hard 22fcd5fd110ba1ff592b4e23013d870831756259 && \
    make -j $(nproc) && \
    mv main /usr/bin/whisper-main && \
    mv server /usr/bin/whisper-server && \
    cd / && \
    rm -rf whisper.cpp
