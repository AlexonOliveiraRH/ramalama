# Base image with CUDA for compilation
FROM docker.io/nvidia/cuda:12.6.2-devel-ubi9 AS builder

ARG LLAMA_CPP_SHA=1329c0a75e6a7defc5c380eaf80d8e0f66d7da78
# renovate: datasource=git-refs depName=ggerganov/whisper.cpp packageName=https://github.com/ggerganov/whisper.cpp gitRef=master versioning=loose type=digest
ARG WHISPER_CPP_SHA=31aea563a83803c710691fed3e8d700e06ae6788

COPY ../scripts /scripts
RUN chmod +x /scripts/*.sh && \
    /scripts/build_llama_and_whisper.sh "cuda" "$LLAMA_CPP_SHA" \
      "$WHISPER_CPP_SHA" "/tmp/install" \
      "-DGGML_CUDA=1" "-DCMAKE_EXE_LINKER_FLAGS=-Wl,--allow-shlib-undefined"

# Final runtime image
FROM docker.io/nvidia/cuda:12.6.2-runtime-ubi9

RUN dnf install -y python3 && \
    dnf clean all && rm -rf /var/cache/*dnf*

# Copy the entire installation directory from the builder
COPY --from=builder /tmp/install /usr

